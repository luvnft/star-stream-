<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="UTF-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />
		<link rel="stylesheet" href="styles.css" />
		<title>p2p streaming</title>
	</head>
	<body>
		<div id="cameraSelector">
			video:
			<select id="camera"></select>
		</div>
		<div id="audioSelector">
			audio:
			<select id="audio"></select>
		</div>
		<button id="takeProfilePicture" type="button" autofocus="true">
			Create Profile Picture
		</button>
		<div>
			<video id="videoTag" autoplay></video>
		</div>
		<canvas id="profilePicCanvas" style="display: none"></canvas>
		<div>
			<img id="profilePicOutput" />
		</div>

		<script>
			var videoArea = document.querySelector('video');
			var videoSelect = document.querySelector('#camera');
			var audioSelect = document.querySelector('#audio');
			// for taking profile picture
			var profilePicCanvas = document.querySelector('#profilePicCanvas');
			var profilePictureOutput = document.querySelector('#profilePicOutput');
			var takePicButton = document.querySelector('#takeProfilePicture');
			var videoTag = document.querySelector('#videoTag');

			var width = 240;
			var height = 0;
			var streaming = false;

			// event listener for taking picture
			takePicButton.addEventListener(
				'click',
				function (event) {
					takeProfilePic();
					event.preventDefault();
				},
				false
			);

			// event listener for can play
			videoTag.addEventListener(
				'canplay',
				function (event) {
					if (!streaming) {
						height = videoTag.videoHeight / (videoTag.videoWidth / width);
						if (isNaN(height)) {
							height = width / (4 / 3);
						}

						videoTag.setAttribute('width', width);
						videoTag.setAttribute('height', height);
						profilePicCanvas.setAttribute('width', width);
						profilePicCanvas.setAttribute('height', height);
						streaming = true;
					}
				},
				false
			);

			// function hamdler for taking pic
			function takeProfilePic() {
				var context = profilePicCanvas.getContext('2d');
				if (width && height) {
					profilePicCanvas.width = width;
					profilePicCanvas.height = height;
					context.drawImage(videoTag, 0, 0, width, height);

					var data = profilePicCanvas.toDataURL('image/png');
					profilePictureOutput.setAttribute('src', data);
				}
			}

			// Get camera sources and audio sources
			// source: https://stackoverflow.com/questions/20110611/mediastreamtrack-getsources-not-supported-in-firefox-how-to-do-the-equivalent
			navigator.mediaDevices
				.enumerateDevices()
				.then(function (devices) {
					devices.forEach(function (device) {
						var option = document.createElement('option');
						option.value = device.deviceId;
						if (device.kind === 'videoinput') {
							option.text = device.label || 'camera' + (videoSelect.length + 1);
							videoSelect.appendChild(option);
						} else if (device.kind == 'audioinput') {
							option.text = device.label || 'mic' + (audioSelect.length + 1);
							audioSelect.appendChild(option);
						}
					});
				})
				.catch(function (err) {
					console.log(err.name + ': ' + err.message);
				});

			startStream();

			// start stream
			function startStream() {
				// because different browsers have different apis for getting audio and video
				navigator.getUserMedia =
					navigator.getUserMedia ||
					navigator.webkitGetUserMedia ||
					navigator.mozGetUserMedia;

				// pass the camera and audio source to the browser
				var videoSource = videoSelect.value;
				var audioSource = audioSelect.value;

				// constraints settings for audio and video
				var constraints = {
					audio: false,
					video: {
						width: { min: 240, ideal: 240 },
						height: { min: 240, ideal: 240 },
						aspectRatio: { ideal: 1.7777777778 },
						frameRate: { max: 16 },
					},
					optional: [
						{
							sourceId: videoSource,
						},
					],
				};

				// handles permision to get the video and audio from user with on onSucces function when user gives browser permission, and handles with error on onError function
				navigator.getUserMedia(constraints, onSuccess, onError);
			}

			// set the video object to <video> element, adds effect
			function onSuccess(stream) {
				console.log('Success! We have a stream');
				videoArea.srcObject = stream;
				videoArea.className = 'grayscale-filter';
				videoArea.play();
			}

			// handles error, e.g when user dinies permission for audio or video
			function onError(error) {
				console.log('Error with getUserMedia: ', error);
			}
		</script>
	</body>
</html>
